{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for loading the data from JSON files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for exporting to a JSON file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(file, data):\n",
    "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for **training** our custom NER NLP model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training.example import Example\n",
    "def train_ner_nlp_model(data, iterations):\n",
    "    TRAIN_DATA = data\n",
    "    nlp = spacy.blank(\"en\") #A new blank ENGLISH NLP object.\n",
    "    #Checking if a NER component already exists in the pipeline.\n",
    "    if(\"ner\" not in nlp.pipe_names): \n",
    "        #Add new NER pipe or else get the existing ner pipe.\n",
    "        ner = nlp.add_pipe(\"ner\")\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    #Creating a list of other pipes, except the NER pipe.\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    #For training our specific pipe, we need to disable other pipes.\n",
    "    with nlp.select_pipes(disable=other_pipes):\n",
    "        optimizer = nlp.initialize()\n",
    "        for itn in range(iterations):\n",
    "            print(\"Starting iteration \" + str(itn))\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "                nlp.update(\n",
    "                    [example],\n",
    "                    sgd=optimizer,\n",
    "                    losses=losses\n",
    "                )\n",
    "            print (losses)\n",
    "        return (nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading up our **training_data** to TRAIN_DATA variable!  \n",
    "Starting then **training** our custom NER NLP model with our training_data!  \n",
    "**Exporting** our trained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = load_data(\"../CustomNER_NLP_Model/data/voicecommander_training_data.json\")\n",
    "nlp = train_ner_nlp_model(TRAIN_DATA, 30) #30 iterations for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exporting** our custom NER NLP model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"voicecommander_custom_ner_nlp_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itâ€™s time to test our custom NER NLP model to see how well it recognizes  \n",
    "our desired entities in **unseen data** (i.e., how well it generalizes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data_text = \"\"\"\n",
    "In the heart of the bustling campus, the library, often referred to as the intellectual hub, stood proudly. \n",
    "As the sun began to set, the duty of illuminating the vast expanse fell upon the lone lamp perched on \n",
    "the librarian's desk. The computer, a source of infinite knowledge, hummed quietly in the corner, \n",
    "waiting to be awakened. Students would often gather in the aula to turn on the projector and the light for presentations, \n",
    "with the remote always seeming to be missing just when it was needed most. In the adjacent gymnasium, \n",
    "the coach would routinely turn off the loudspeaker once the game had ended. Meanwhile, the science lab \n",
    "was a domain of exploration, where students would put on their goggles and gloves, ready to dive into \n",
    "the world of experiments.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
